{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "df_test = pd.read_csv('test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('[\\W]+', ' ', text.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['text'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "df_train['author'] = class_le.fit_transform(df_train['author'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df_train.iloc[:, df_train.columns.get_loc('text')].values, \\\n",
    "       df_train.iloc[:, df_train.columns.get_loc('author')].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   test_size=0.3,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "def tokenizer_lemma(text):\n",
    "    return [lemma.lemmatize(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "bag_1gram_lr_pipe = pickle.load(open(os.path.join('pkl_objects', 'bag_1gram_lr_pipe.pkl'), 'rb'))\n",
    "bag_2gram_lr_pipe = pickle.load(open(os.path.join('pkl_objects', 'bag_2gram_lr_pipe.pkl'), 'rb'))\n",
    "\n",
    "tfidf_1gram_lr_pipe = pickle.load(open(os.path.join('pkl_objects', 'tfidf_1gram_lr_pipe.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_hard_clf = VotingClassifier(\n",
    "                                estimators=[\n",
    "                                    ('bag_1gram', bag_1gram_lr_pipe), \n",
    "                                    ('bag_2gram', bag_2gram_lr_pipe), \n",
    "                                    ('tfidf_1gram', tfidf_1gram_lr_pipe)\n",
    "                                ],\n",
    "                                voting='hard')\n",
    "\n",
    "voting_soft_clf = VotingClassifier(\n",
    "                                estimators=[\n",
    "                                    ('bag_1gram', bag_1gram_lr_pipe), \n",
    "                                    ('bag_2gram', bag_2gram_lr_pipe), \n",
    "                                    ('tfidf_1gram', tfidf_1gram_lr_pipe)\n",
    "                                ],\n",
    "                                voting='soft')\n",
    "\n",
    "voting_hard_clf.fit(X_train, y_train)\n",
    "voting_soft_clf.fit(X_train, y_train)\n",
    "\n",
    "all_clf = [bag_1gram_lr_pipe, \n",
    "           bag_2gram_lr_pipe, \n",
    "           tfidf_1gram_lr_pipe, \n",
    "           voting_hard_clf, \n",
    "           voting_soft_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=['i', 'me'...alty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))]) 0.700374531835206\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        stri...alty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]) 0.48927477017364657\n",
      "Pipeline(memory=None,\n",
      "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm=None, preprocessor=None, smooth_idf=True,\n",
      " ...alty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]) 0.7851549199863807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('bag_1gram', Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1,...y='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]))],\n",
      "         flatten_transform=None, n_jobs=1, voting='hard', weights=None) 0.716207013959823\n",
      "VotingClassifier(estimators=[('bag_1gram', Pipeline(memory=None,\n",
      "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1,...y='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]))],\n",
      "         flatten_transform=None, n_jobs=1, voting='soft', weights=None) 0.7361252979230507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (all_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf, accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
